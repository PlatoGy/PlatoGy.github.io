---
layout: post
title: GPUç¼–ç¨‹PPT3
author: Patrick Gao
date: 2025-04-08 14:04
categories:
  - MISCADA
  - GPU Course
tags:
  - GPU Programming
mermaid: true
math: true
pin: false
---
# Parallel Programming Models: OpenMP

**Course**: COMP52315 GPU Programming  
**Lecturer**: Christopher Marcotte  
ğŸ“§ christopher.marcotte@durham.ac.uk

---

## ğŸ“Œ Recap

- åŸºç¡€ CUDA ç¼–ç¨‹æ–¹æ³•
- CUDA ä¼˜åŒ–æŠ€æœ¯ï¼š
  - é¿å…åˆ†æ”¯å‘æ•£
  - ä½¿ç”¨å…±äº«å†…å­˜
- CUDA ä¸­çš„ä»»åŠ¡å¹¶è¡Œè¡¨è¾¾æ–¹å¼ï¼š
  - åŠ¨æ€å¹¶è¡Œ
  - å¼‚æ­¥ä»»åŠ¡å›¾

---

## ğŸ’¡ OpenMP ç®€ä»‹

- OpenMP æ˜¯ä¸€ç§å¹¶è¡Œç¼–ç¨‹æ¨¡å‹ï¼Œæ”¯æŒ C/C++/Fortran è¯­è¨€ã€‚
- æ”¯æŒ CPU å’Œ GPU æ¶æ„ä¸Šçš„å¯æ‰©å±•æ€§ä¸å¯ç§»æ¤æ€§ã€‚
- å½“å‰ç‰ˆæœ¬ï¼š5.2ï¼Œæœ¬è¯¾ç¨‹åŸºäº **OpenMP 4.5**ï¼ˆNvidia HPC SDK æ”¯æŒï¼‰ã€‚

ğŸ“– å‚è€ƒèµ„æ–™ï¼š
- [OpenMP 4.5 è§„èŒƒ](https://www.openmp.org/wp-content/uploads/openmp-4.5.pdf)
- [Cheat Sheet](https://www.openmp.org/wp-content/uploads/OpenMP-4.5-1115-CPP-web.pdf)

---

## ğŸ§  æ¶æ„å’Œå†…å­˜æ¨¡å‹

```
Host (CPU)                Target (GPU)
 Main Memory    â‡„ Bus â‡„  Global Memory
```

- Host è®¾å¤‡è¿è¡Œ OpenMP ç¨‹åºä¸»çº¿ç¨‹
- Target è®¾å¤‡å¯é€šè¿‡ OpenMP æŒ‡ä»¤è¿›è¡Œä»£ç å’Œæ•°æ® offload
- æ•°æ®ä¼ è¾“å¯ä»¥ç”±è¿è¡Œæ—¶è‡ªåŠ¨å®Œæˆï¼Œä¹Ÿå¯ä»¥æ˜¾å¼ç®¡ç†

---

## ğŸ” æ‰§è¡Œæ¨¡å‹

- åŸºäº Fork-Joinï¼šå¹¶è¡Œé˜¶æ®µ + é¡ºåºé˜¶æ®µ
- Host-centricï¼šä¸»çº¿ç¨‹åœ¨ Host æ‰§è¡Œï¼Œoffload åˆ° Target
- æ”¯æŒå±‚æ¬¡åŒ–å¹¶è¡Œï¼š
  - `parallel` è¡¨ç¤ºçº¿ç¨‹å—
  - `teams` è¡¨ç¤ºçº¿ç¨‹å—ç½‘æ ¼

---

## ğŸ§± ç¼–ç¨‹æ¨¡å‹

OpenMP ä½¿ç”¨ **directiveï¼ˆæŒ‡ä»¤ï¼‰**é©±åŠ¨ç¼–ç¨‹æ–¹å¼ï¼š

```cpp
#pragma omp directive-name [clauses]
```

- æŒ‡ä»¤åªèƒ½åº”ç”¨äºä¸€ä¸ªç»“æ„åŒ–ä»£ç å—ï¼ˆå¦‚èŠ±æ‹¬å·æ‹¬èµ·æ¥ï¼‰
- clause é¡ºåºä¸æ•æ„Ÿï¼Œå¯ä»¥é‡å¤ä½¿ç”¨

---

## âš™ï¸ GPU ç¼–ç¨‹æ¨¡å‹

- GPU åŒ…å«å¤šä¸ª SIMD è®¡ç®—å•å…ƒï¼ˆCUï¼‰
- æŒ‡ä»¤ç”¨æ³•ï¼š
  - `#pragma omp teams`ï¼šåˆ›å»ºå¤šä¸ªçº¿ç¨‹ teamï¼ˆä½¿ç”¨å¤šä¸ª CUï¼‰
  - `#pragma omp parallel`ï¼šåˆ›å»ºçº¿ç¨‹ teamï¼ˆä½¿ç”¨å¤šä¸ª laneï¼‰
  - `#pragma omp target`ï¼šåœ¨ GPU ä¸Šæ‰§è¡Œï¼Œéšå¼æ•°æ®ä¼ è¾“

> âš ï¸ æ— æ³•è®¿é—® CUDA çš„ä½çº§ç‰¹æ€§ï¼ˆå¦‚ `__shared__`ï¼Œ`threadIdx.x`ï¼‰

---

## ğŸ§® æ•°æ®å¹¶è¡ŒæŒ‡ä»¤

### ğŸ”¹ ç”Ÿæˆå¹¶è¡Œ

```cpp
#pragma omp parallel
#pragma omp teams
```

### ğŸ”¹ åˆ†é…å·¥ä½œ

```cpp
#pragma omp for
#pragma omp distribute
```

### ğŸ”¹ ç»„åˆæ„é€ ï¼ˆç®€å†™ï¼‰

```cpp
#pragma omp parallel for
#pragma omp teams distribute
#pragma omp teams distribute parallel for
```

---

## ğŸ“¤ æ˜¾å¼æ•°æ®ä¼ è¾“

```cpp
#pragma omp target map(map-type : list)
```

- `map-type`: `to`, `from`, `tofrom`
- `list`: è¦ä¼ è¾“çš„æ•°ç»„åˆ‡ç‰‡

**ç¤ºä¾‹**ï¼š

```cpp
#pragma omp target map(tofrom : A[0:N], B[0:M])
```

---

## ğŸ“¦ æŒä¹…æ•°æ®æ˜ å°„

ç»“æ„åŒ–æ•°æ®ï¼š

```cpp
#pragma omp target data map(...)
```

éç»“æ„åŒ–æ•°æ®ï¼ˆå¦‚ struct/classï¼‰ï¼š

```cpp
#pragma omp target enter data map(...)
#pragma omp target exit data map(...)
```

---

## ğŸ§ª ç¤ºä¾‹ï¼šå‘é‡åŠ æ³•

```cpp
#pragma omp target teams distribute parallel for     map(to: X[0:N], Y[0:N]) map(tofrom: Z[0:N])
for(int i = 0; i < N; i++) {
    Z[i] = X[i] + Y[i];
}
```

â†’ ä¸¤å±‚å¹¶è¡Œï¼šçº¿ç¨‹å’Œçº¿ç¨‹å›¢é˜Ÿ

---

## â• ç¤ºä¾‹ï¼šå¹¶è¡Œå½’çº¦

```cpp
#pragma omp target teams distribute parallel for     reduction(+:sum)
for (int i = 0; i < N; i++) {
    sum = sum + X[i];
}
```

ğŸ“˜ è‡ªå­¦æ¨èï¼š[CUDA Reduction](https://developer.download.nvidia.com/assets/cuda/files/reduction.pdf)

---

## âš’ï¸ ä»»åŠ¡å¹¶è¡ŒæŒ‡ä»¤

```cpp
#pragma omp task [clauses]
```

- å¤šçº¿ç¨‹å¯ç”Ÿæˆä»»åŠ¡ï¼Œéœ€ä½¿ç”¨ `#pragma omp single` é™åˆ¶
- ä½¿ç”¨ `#pragma omp barrier` ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ

### ğŸ”¹ ä¾èµ–å…³ç³»

```cpp
#pragma omp task depend(in|out: list)
```

- `in`ï¼šè¯»å–æ•°æ®
- `out`ï¼šå†™å…¥æ•°æ®

ğŸ“˜ æ¨èé˜…è¯»ï¼š[OpenMP Tasking Dependencies](https://blog.rwth-aachen.de/itc-events/files/2021/02/11-openmp-CT-tasking_dependencies.pdf)

---

## ğŸ“Œ ç¤ºä¾‹ï¼šOpenMP Tasks

```cpp
int x = 0, y = 0, z = 0;

#pragma omp parallel
#pragma omp single
{
    #pragma omp task depend(out: x)
    { x = 1; }

    #pragma omp task depend(in: x)
    { y = 2 * x; }

    #pragma omp task depend(in: x)
    { z = 1 + x; }

    #pragma omp task depend(out: x) depend(in: y,z)
    { x = y + z; }
}
```

---

## âœ… ç¼–ç¨‹å»ºè®®

### ğŸ›  ç¼–å†™æµç¨‹

1. è®¾ç½®æ‰§è¡Œç¯å¢ƒï¼ˆé»˜è®¤ CPUï¼‰
2. ç”Ÿæˆå¹¶è¡Œç»“æ„ï¼ˆ`teams`, `parallel`ï¼‰
3. åˆ†é…å·¥ä½œï¼ˆå¦‚ `for`, `distribute`ï¼‰
4. ä½¿ç”¨ `map`, `enter data` ç­‰è¿›è¡Œæ•°æ®ç®¡ç†ä¼˜åŒ–

---

## ğŸ§ª ç¼–è¯‘ä¸æ‰§è¡Œ

- æ”¯æŒç¼–è¯‘å™¨ï¼š`gcc/g++`, `clang/clang++`, `nvc++`ï¼ˆé `nvcc`ï¼‰

**ç¤ºä¾‹å‘½ä»¤**ï¼š

```bash
module load nvidia-hpc
nvc++ -fopenmp -mp=gpu my_omp.cpp -o exe
OMP_NUM_THREADS=1 OMP_NUM_TEAMS=1 ./exe
```

---

## ğŸ” æœ€ä½³å®è·µ

1. å……åˆ†æŒ–æ˜å¹¶è¡Œæ€§ï¼ˆå¦‚ collapseï¼Œtaskingï¼‰
2. å¹¶è¡Œç²’åº¦æ¨ªå‘ + çºµå‘å¹¶ç”¨ï¼ˆè®¾ç½®çº¿ç¨‹æ•°/å›¢é˜Ÿæ•°ï¼‰
3. é¿å…ä¸å¿…è¦çš„æ•°æ®ä¼ è¾“
4. ä¸å»ºè®®åœ¨åµŒå¥—å‡½æ•°æˆ–ç¼–è¯‘å•å…ƒä¸­ç”Ÿæˆå¹¶è¡Œ
5. OpenMP target ä»£ç ä¸­ä¸å¯ä½¿ç”¨æ ‡å‡†åº“

