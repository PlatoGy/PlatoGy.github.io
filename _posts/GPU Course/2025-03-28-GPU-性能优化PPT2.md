---
layout: post
title: æ€§èƒ½ä¼˜åŒ–PPT2
author: Patrick Gao
date: 2025-03-28 03:23
categories:
  - MISCADA
  - GPU Course
tags:
  - GPU Programming
mermaid: true
math: true
pin: false
---
# ğŸ“š Session 2: Memory Hierarchy

**Lecturer**: Anne Reinarz

---

## ğŸ§ª Exercise 1: Sum Reduction Benchmark

- **SIMD**: 4 plateaus
- **Scalar**: 3 plateaus
- **Performance variability** caused by **CPU Boosting**

### â“ Why SIMD doesn't reach peak performance?

- **Not** due to instruction throughput
- **Memory bandwidth** decreases with vector size

---

## ğŸ§  Memory Hierarchy Overview

### Types of Memory:

1. **Small and fast**
2. **Large and slow**

> Physics prevents memory from being both large and fast.

**Optimization strategy**:

- Restructure algorithms to **keep data in fast memory**

ğŸ”— [Latency reference by Colin Scott](https://colin-scott.github.io/personal_website/research/interactive_latency.html)

---

## ğŸ—‚ï¸ Cache Memory

### Features:

- Hierarchy of small, fast memory
- Stores frequently accessed data

### Issues:

- Frequently accessed data is **unknown beforehand**
- Use **principle of locality** to predict

---

## ğŸ“ Principle of Locality

### ğŸ•’ Temporal Locality

- If data is accessed now, it will likely be accessed again **soon**

### ğŸ—ºï¸ Spatial Locality

- If one address is accessed, nearby addresses will likely be accessed

---

## ğŸ“¥ Cache Access Behavior

- **First access**:
  - Load from main memory to register
  - Store in cache
- **Subsequent accesses**:
  - Load from cache (faster)

---

## ğŸ§® Example: Sum Reduction

```c
float s[16] = 0;
for (i = 0; i < N; i++) {
  s[i%16] += a[i];
}
```

- `s`: good **temporal locality**
- `a`: good **spatial locality**

---

## ğŸ§° Cache Design Questions

1. Where to put loaded data?
2. How to check if data is in cache?
3. What to do when cache is full?

- Address broken into:
  - **Tag**
  - **Index**
  - **Offset**

---

## ğŸ“Œ Direct Mapped Cache

- Each address maps to **one specific cache slot**
- Conflict resolution: **newer replaces older** (LRU)

---

## ğŸ“ Cache Line Size

- Data is loaded one cache line at a time
- 64 bytes is typical
- Optimize algorithms to use **cache-line-sized chunks**

---

## ğŸ”„ Cache Thrashing Example

```c
int a[64], b[64], r = 0;
for (int i = 0; i < 100; i++)
  for (int j = 0; j < 64; j++)
    r += a[j] + b[j];
```

- Although cache is big enough, **a[j] and b[j] map to the same cache line**, causing conflict.

---

## ğŸ§© Cache Associativity Types

| Type              | Description                             |
| ----------------- | --------------------------------------- |
| Direct Mapped     | One memory block maps to one cache line |
| Fully Associative | Can go anywhere, costly to implement    |
| Set Associative   | N-way set (common values: 2, 4, 8, 16)  |

---

## ğŸ“Š Exercise 2 & 3: Bandwidth vs Array Size

### Bandwidth from different levels:

- **L1** (<32KB): ~370GB/s
- **L2** (<512KB): ~100GB/s
- **L3** (<16MB): ~78GB/s
- **RAM**: ~17.5GB/s

> Performance decreases as data moves away from CPU.

---

## ğŸ§  Summary: Hardware Architecture Insights

### Key Factors:

- Instruction count
- Execution efficiency
- Data movement time

### Hardware Parallelism:

- **Sockets**: 1â€“4 CPUs
- **Cores**: 4â€“32 per CPU
- **Vectorization**: 2â€“16 floats per vector
- **Superscalar**: 2â€“8 instructions per cycle



## ğŸ§  Direct Mapped Caches: Indexing Explained

### ğŸ¯ Goal

Understand how a memory address is split into **Tag**, **Index**, and **Offset** in a Direct Mapped Cache.

---

### ğŸ“¦ Imagine the Cache as Slots

Suppose we have **8 cache slots** labeled 0 to 7:

```
+-------+-------+-------+-------+-------+-------+-------+-------+
| slot0 | slot1 | slot2 | slot3 | slot4 | slot5 | slot6 | slot7 |
+-------+-------+-------+-------+-------+-------+-------+-------+
```

When we load data from memory, we must decide:

- **Which slot** to put it in â†’ this is the **Index**
- **How to recognize** if the data in the slot is correct â†’ this is the **Tag**

---

### ğŸ§® Splitting the Address

Imagine an 8-bit memory address:

```
Address: 1101 0110
```

We divide it into three parts:

#### âœ… 1. Byte Offset (lowest bits)

These bits tell **which byte** inside the cache line we want.

- If cache line = 4 bytes â†’ we need **2 bits**
- In this example: `Offset = 10`

---

#### âœ… 2. Cache Index (middle bits)

These bits tell us **which cache slot** to use.

- If cache has 8 slots â†’ need **3 bits**
- In this example: `Index = 101` â†’ means **slot 5**

---

#### âœ… 3. Tag (highest bits)

These bits are used to **identify** the data stored in that slot.

- In this example: `Tag = 110`

---

### ğŸ“Œ Final Breakdown:

```
Address:       1101 0110
               â†‘    â†‘   â†‘
          Tag=110 Index=101 Offset=10
```

- Put the data in **slot 5**
- When we check slot 5 later, compare its tag with **110**
- If it matches â†’ **cache hit**
- If not â†’ **cache miss**

---

### ğŸ” Example of Conflict

```
&a[0] = 1101 0110
&b[0] = 0101 0110
```

- Both have `Index = 101` â†’ both map to **slot 5**
- But `Tag` is different (110 vs 010)

So:
- Access `a[0]` â†’ slot 5 now has tag = 110
- Then access `b[0]` â†’ overwrites slot 5 with tag = 010
- Re-access `a[0]` â†’ tag mismatch â†’ cache miss

ğŸ¢ This causes **cache thrashing** â€” constant replacement and reloading!

---

### âœ… Summary Table

| Part      | What it does                             |
|-----------|-------------------------------------------|
| Tag       | Uniquely identifies the memory block      |
| Index     | Selects which cache slot to use           |
| Offset    | Selects which byte within the cache line  |

---

